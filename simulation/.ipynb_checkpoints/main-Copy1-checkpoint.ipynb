{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e5de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import simulate_clsna, visualize, visualize_membership, preprocess, ClsnaModel\n",
    "import numpy as np\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6ff449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# writer = SummaryWriter(log_dir='../runs/exp2', comment = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3f74c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494c4f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "DIM = 2\n",
    "T = 10\n",
    "SIGMA = 1\n",
    "TAU = 1\n",
    "ALPHA = 1\n",
    "DELTA = 2\n",
    "GAMMAW = 0.25\n",
    "GAMMAB = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a7516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "z,y,Aw,Ab=simulate_clsna(N=N,d=DIM,T=T,alpha=ALPHA,delta=DELTA,sigma=SIGMA, tau=TAU, gammaw=GAMMAW, gammab=GAMMAB)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada50d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.concatenate(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecf7c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(z_hat=z,z_true=z,start=N*3,end=N*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f229ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "membership = np.concatenate((np.ones(N//2),np.zeros(N//2)))\n",
    "visualize_membership(z=z,membership=np.tile(membership,T),start=9*N,end=10*N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65101039",
   "metadata": {},
   "outputs": [],
   "source": [
    "label, persist, Aw, Ab, combination_N=preprocess(y, Aw, Ab, N, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e241c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "_s = torch.arange(0,N*(T-1), requires_grad = False)\n",
    "_t = torch.arange(N,N*T, requires_grad = False)\n",
    "ar_pair = torch.stack((_s,_t), dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71493e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015ffc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_N = combination_N.to(device)\n",
    "label = label.to(device)\n",
    "persist = persist.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eadeb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClsnaModel(device,N,T,ar_pair,Aw,Ab).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d647f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():       \n",
    "    model.z[:,:] = torch.from_numpy(z).to(device)\n",
    "    #logsigma2\n",
    "    model.para[0,0] = model.para[0,0].clip(min=2*math.log(SIGMA), max=2*math.log(SIGMA))\n",
    "    #logtau2\n",
    "    model.para[1,0] = model.para[1,0].clip(min=2*math.log(TAU), max=2*math.log(TAU))\n",
    "    #gamma\n",
    "    model.para[1,1] = model.para[1,1].clip(min=GAMMAW, max=GAMMAW)\n",
    "    model.para[2,0] = model.para[2,0].clip(min=GAMMAB, max=GAMMAB)\n",
    "    #alpha\n",
    "    model.para[0,1] = model.para[0,1].clip(min=ALPHA, max=ALPHA)\n",
    "    #delta\n",
    "    model.para[2,1] = model.para[0,1].clip(min=DELTA, max=DELTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffa039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([model.z, model.para], lr=0.2, momentum = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab39c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(optimizer):\n",
    "    optimizer.zero_grad()   \n",
    "    t_index=torch.arange(start=0,end=N*T,device=device,requires_grad=False)\n",
    "    # take loss, calculate grad\n",
    "    # use sign of the grad for global parameters, take SGD step\n",
    "    loss = model.loss(device=device,label=label,persist=persist,sample_edge=combination_N,T_index=t_index)\n",
    "    loss.backward()\n",
    "    model.para.grad = 0.1*((model.para.grad>0).bool().float()-0.5)\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18227ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(optimizer):\n",
    "    for epoch in range(1,1000000):\n",
    "        loss = train(optimizer)\n",
    "        if epoch%2000==0:\n",
    "            optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr']-0.01\n",
    "        if epoch%1111== 0:\n",
    "            tt = epoch%T\n",
    "            z_hat, p_hat = model()\n",
    "            z_hat = z_hat.detach().cpu().numpy()\n",
    "            p_hat = p_hat.detach().cpu().numpy().round(2)\n",
    "            caption_dict = {'E':epoch,\n",
    "                            'T':tt,\n",
    "                            'a':p_hat[0,1],\n",
    "                            'd':p_hat[2,1],\n",
    "                            'gw':p_hat[1,1],\n",
    "                            'gb':p_hat[2,0],\n",
    "#                             's':round(math.exp(p_hat[0,0])**0.5,1),\n",
    "#                             't':round(math.exp(p_hat[1,0])**0.5,1),\n",
    "                           'lr':round(optimizer.param_groups[0]['lr'],2),\n",
    "                           'loss':round(loss,1)}\n",
    "            start = tt*N\n",
    "            end = (tt+1)*N\n",
    "            visualize(z_hat=z_hat,z_true=z[:,[1,0]],start=start,end=end,caption=str(caption_dict))\n",
    "#             visualize(z_hat=z_hat,z_true=z,start=start,end=end,caption=str(caption_dict))\n",
    "            \n",
    "            \n",
    "            \n",
    "#             writer.add_scalar(\"Plot/logL\", loss, epoch)\n",
    "# #             writer.add_scalar(\"Plot/alpha\", alpha, epoch)\n",
    "#             writer.add_scalar(\"Plot/lr\", optimizer.param_groups[0]['lr'], epoch)\n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da85891",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd54e3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba14c886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_train(optimizer,index,fixed):\n",
    "    optimizer.zero_grad()   \n",
    "    t_index=torch.arange(start=0,end=N*T,device=device,requires_grad=False)\n",
    "    loss = model.loss(device=device,label=label,persist=persist,sample_edge=combination_N,T_index=t_index)\n",
    "    loss.backward()\n",
    "    model.para.grad = 0.2*((model.para.grad>0).bool().float()-0.5)\n",
    "    optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        model.para[index//2,index%2] = fixed\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c5d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_run(index,fixed,logL_df):\n",
    "    #initialize model\n",
    "    model = ClsnaModel(device,N,T,ar_pair,Aw,Ab).to(device)\n",
    "    with torch.no_grad():       \n",
    "        model.embedding[:,:] = embed_star.detach().clone()\n",
    "        model.para[:,:] = para_star.detach().clone()    \n",
    "    #create optimizer\n",
    "    optimizer = torch.optim.SGD([model.embedding, model.para], lr=1e-1, momentum = 0.97)\n",
    "    #initalize list\n",
    "    logL = []\n",
    "    for epoch in range(1,1000000):\n",
    "        loss = fix_train(optimizer,index,fixed)\n",
    "        if (epoch>4000) and (epoch%100 == 0):\n",
    "            logL.append(loss)\n",
    "    logL_df[fixed] = logL\n",
    "    print(logL_df.mean().tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
